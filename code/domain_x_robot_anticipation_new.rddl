domain domain_x_robot_anticipation_new {

    types {
        location : object;
        item : object;
        agent : object;
        human: object;
        phase_type : { @phase0, @phase1, @phase2 };
    };

    pvariables {
        // State fluents
        current_phase : { state-fluent, phase_type, default = @phase0 };


        agent-loc(agent, location)			: { state-fluent, bool, default = false }; // agent at location
        human-loc(human, location)			: { state-fluent, bool, default = false }; // agent at location
        
        obj-loc(item, location)  : { state-fluent, bool, default = false };
        inhand(agent, item)      : { state-fluent, bool, default = false };
        inhand-human(human, item)      : { state-fluent, bool, default = false };
        obj-break(item)          : { state-fluent, bool, default = false };
        cleaned(location)        : { state-fluent, bool, default = true };
        food-in(item, item)					: { state-fluent, bool, default = false }; // item in receptacle or appliance
		
        switch_appliance(location)			: { state-fluent, bool, default = false };
        open(location)                      : { state-fluent, bool, default = false };

        // Action fluents
        move(agent, location, location) : { action-fluent, bool, default = false };
        move_human(human, location, location) : { action-fluent, bool, default = false };
        pick(agent, item, location)     : { action-fluent, bool, default = false };
        pick_human(human, item, location)     : { action-fluent, bool, default = false };
        place(agent, item, location)    : { action-fluent, bool, default = false };
        place_human(human, item, location)    : { action-fluent, bool, default = false };
        clean(agent, location)          : { action-fluent, bool, default = false };
        clean_human(human, location)          : { action-fluent, bool, default = false };
        put_in(agent, item, item)			: { action-fluent, bool, default = false }; // put object in receptacle
        put_in_human(human, item, item)			: { action-fluent, bool, default = false }; // put object in receptacle

        agent_switch_on(agent, location)			: { action-fluent, bool, default = false };
	    agent_switch_off(agent, location)		: { action-fluent, bool, default = false };
        human_switch_on(human, location)			: { action-fluent, bool, default = false };
	    human_switch_off(human, location)		: { action-fluent, bool, default = false };

        agent_open(agent, location)			: { action-fluent, bool, default = false };
	    agent_close(agent, location)		: { action-fluent, bool, default = false };
        human_open(human, location)			: { action-fluent, bool, default = false };
	    human_close(human, location)		: { action-fluent, bool, default = false };

        // Non-fluent variables
        COST(agent, location, location) : { non-fluent, int, default = 0 };
        FRAGILE(item)                   : { non-fluent, bool, default = false };
        MOP_ITEM(item)                  : { non-fluent, bool, default = false };
        FOOD_ITEM(item)                 : { non-fluent, bool, default = false };
        EQUAL(item, item)               : { non-fluent, bool, default = false };
        GOAL_0(item, item, location)      : { non-fluent, bool, default = false };
        GOAL_1(item, item, location)      : { non-fluent, bool, default = false };
        GOAL_2(item, item, location)      : { non-fluent, bool, default = false };
        DESTINATION_0(item, location)     : { non-fluent, bool, default = false };
        DESTINATION_1(item, location)   : { non-fluent, bool, default = false };
        DESTINATION_2(item, location)   : { non-fluent, bool, default = false };
        //DESTINATION_3(item, location)   : { non-fluent, bool, default = false };
        CONTAINER(item)                 : { non-fluent, bool, default = false };
        //GOAL_LOCATION(location)         : {  non-fluent, bool, default = false };

        APPLIANCE(location)                 : { non-fluent, bool, default = false };

    };

    cpfs {

        current_phase' =
            // Once we are in @phase0 and see that an item meets DESTINATION_0,
            // transition to @phase1
            if (current_phase == @phase0
                & exists_{?i : item, ?l : location}
                    (obj-loc'(?i, ?l) & DESTINATION_0(?i, ?l)))
            then @phase1
            
            // Once we are in @phase1 and see that an item meets DESTINATION_1,
            // transition to @phase2
            else if (current_phase == @phase1
                     & exists_{?i : item, ?l : location}
                         (obj-loc'(?i, ?l) & DESTINATION_1(?i, ?l)))
            then @phase2
            
            // Otherwise, remain in the current phase
            else current_phase;



                human-loc'(?h, ?l) =
                // If the human decides to move FROM a location
                if (exists_{?from : location} (move_human(?h, ?from, ?l) ^ human-loc(?h, ?from))) 
                    then Bernoulli(0.8)  // 80% chance they reach `?l`
                
                // Did it leave ?l and become false?
                else if (exists_{?to : location} (move_human(?h, ?l, ?to) ^ human-loc(?h, ?l)))
                    then false
                    
                // If no movement happens, the human stays in their current location
                else 
                    human-loc(?h, ?l);
        
    
    
            inhand'(?a, ?i) =
                if ( exists_{?l : location}( pick(?a, ?i, ?l) ^ agent-loc(?a, ?l) ))
                    then true
                else if(exists_{?l : location}(place(?a, ?i, ?l) ))
                    then false
                else if(exists_{?l : location, ?f : item}(put_in(?a, ?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i) ))
                    then false
                else if(exists_{?h:human} (inhand-human(?h, ?i)))
                    then false
                else
                    inhand(?a, ?i);
    
            inhand-human'(?h, ?i) =
                if (exists_{?l : location}( pick_human(?h, ?i, ?l) ^ human-loc(?h, ?l) ^ FRAGILE(?i)))
                    then Bernoulli(0.1)
                else if (exists_{?l : location}( pick_human(?h, ?i, ?l) ^ ~FRAGILE(?i)))
                    then Bernoulli(0.9)
                else if(exists_{?l : location}(place_human(?h, ?i, ?l) ))
                    then false
                else if(exists_{?l : location, ?f : item}(put_in_human(?h, ?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i)))
                    then false
                else if(exists_{?a:agent} (inhand(?a, ?i)))
                    then false
                else
                    inhand-human(?h, ?i);
    
            obj-break'(?i) = 
                if(exists_{?h : human, ?l : location} ((pick_human(?h, ?i, ?l) ) ^ FRAGILE(?i)))
                    then Bernoulli(0.9)
                else if(exists_{?h : human, ?l : location, ?f : item} ((place_human(?h, ?i, ?l) | inhand-human(?h, ?i)) | (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in_human(?h, ?f, ?i) | inhand-human(?h, ?i)) ^ FRAGILE(?i) ))
                    then Bernoulli(0.9)
                else if(exists_{?a: agent, ?l : location} (pick(?a, ?i, ?l)))
                    then false
                else if(exists_{?a : agent, ?l : location} (place(?a, ?i, ?l) | inhand(?a, ?i)))
                    then false
                else if(exists_{?a : agent, ?l : location, ?f :  item} (put_in(?a, ?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i) | inhand(?a, ?i)))
                    then false
                else if (exists_{?h: human, ?l : location} (pick_human(?h, ?i, ?l) ^ ~FRAGILE(?i)))
                    then Bernoulli(0.1)
                else if(exists_{?h : human, ?l : location, ?f: item} ((place_human(?h, ?i, ?l) | inhand-human(?h, ?i)) | (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in_human(?h, ?f, ?i) | inhand-human(?h, ?i))  ^ ~FRAGILE(?i) ))
                    then Bernoulli(0.1)
                else
                    false;
    
            food-in'(?f, ?i) = 
                if (exists_{?a : agent} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in(?a, ?f, ?i) ^ inhand(?a, ?f) ))
                    then true
                else if (exists_{?h : human} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in_human(?h, ?f, ?i) ^ inhand-human(?h, ?f) ))
                    then true
                else
                    food-in(?f, ?i);
    
            obj-loc'(?i, ?l) = 
                if (exists_{?a : agent} (pick(?a, ?i, ?l)))
                    then false  // Robot picked up the item, remove from location
                else if (exists_{?h : human} (pick_human(?h, ?i, ?l) ))
                    then false  // Human picked up the item, remove from location
                else if (exists_{?a : agent} (place(?a, ?i, ?l)))
                    then true  // The item in the robot's hand is in obj-loc
                else if (exists_{?a : agent, ?f: item} (put_in(?a, ?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i)))
                    then true  
                else if (exists_{?a: agent} (inhand(?a, ?i)))
                    then false
                else if (exists_{?h : human} (place_human(?h, ?i, ?l)))
                    then true  // The item is now in the human's hand
                else if (exists_{?h : human, ?f: item} (put_in_human(?h, ?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i)))
                    then true  
                else if (exists_{?h : human} (inhand-human(?h, ?i)))
                    then false
                else obj-loc(?i, ?l);  // Otherwise, the item stays in the same location
                
    
    
            
    
            agent-loc'(?a, ?l) = 		
                // Did it move to ?l and become true?
                if (exists_{?from : location} (move(?a, ?from, ?l) ^ agent-loc(?a, ?from)))
                    then true
                
                // Did it leave ?l and become false?
                else if (exists_{?to : location} (move(?a, ?l, ?to) ^ agent-loc(?a, ?l)))
                    then false
                    
                // It didn't move, so it's current value persists (frame axiom)
                else 
                    agent-loc(?a, ?l);
    
            cleaned'(?l) = 
                if (exists_{?i : item, ?a: agent} (obj-break(?i) ^ obj-loc(?i, ?l) ^ agent-loc(?a, ?l) ^ ~exists_{?m: item} (MOP_ITEM(?m) ^ obj-loc(?m, ?l) ^ agent-loc(?a, ?l))))
                    then false  //Location remains dirty if no mop is there
    
                else if (exists_{?i : item, ?h: human} (obj-break(?i) ^ obj-loc(?i, ?l) ^ human-loc(?h, ?l) ^ ~exists_{?m: item} (MOP_ITEM(?m) ^ obj-loc(?m, ?l) ^ human-loc(?h, ?l))))
                    then false  //Location remains dirty if no mop is there
    
                else if (exists_{?a : agent, ?i : item} (clean(?a, ?l) ^ agent-loc(?a, ?l) ^ obj-loc(?i, ?l) ^ MOP_ITEM(?i)))
                    then true  // Location gets cleaned when using a mop
    
                else if (exists_{?h : human, ?i : item} (clean_human(?h, ?l) ^ human-loc(?h, ?l) ^ obj-loc(?i, ?l) ^ MOP_ITEM(?i)))
                    then true  // Location gets cleaned when using a mop
    
                else
                    cleaned(?l);

        switch_appliance'(?l) = 
			if (exists_{?a : agent} (agent_switch_on(?a, ?l) ^ APPLIANCE(?l)))
				then true
			else if (exists_{?a : agent} (agent_switch_off(?a, ?l) ^ APPLIANCE(?l) ))
				then false
			else if (exists_{?h : human} (human_switch_on(?h, ?l) ^ APPLIANCE(?l) ))
				then Bernoulli(0.9)
			else if (exists_{?h : human} (human_switch_off(?h, ?l) ^ APPLIANCE(?l) ))
				then Bernoulli(0.1)
			else
				switch_appliance(?l);
		
        open'(?obj) = 
			if (exists_{?a : agent} (agent_open(?a, ?obj) ^ APPLIANCE(?obj)))
				then true
			else if (exists_{?a : agent} (agent_close(?a, ?obj) ^ APPLIANCE(?obj)))
				then false
			else if (exists_{?h : human} (human_open(?h, ?obj) ^ APPLIANCE(?obj)))
				then Bernoulli(0.8)
			else if (exists_{?h : human} (human_close(?h, ?obj) ^ APPLIANCE(?obj)))
				then Bernoulli(0.2)
			else
				open(?obj);
        
    };


// reward = // Task related reward
// 			//50 * [sum_{?f: food} exists_{?l : location} (obj-loc(?f, ?l) ^ DESTINATION(?f, ?l)) ]
// 			//+ 50 * [sum_{?i: item} exists_{?i2:item, ?l : location} [(obj-loc'(?i, ?l) ^ DESTINATION_2(?i, ?l) ^ ~obj-break'(?i) ^ cleaned'(?l)) |
// 			(obj-loc'(?i2, ?l) ^ EQUAL(?i, ?i2) ^ DESTINATION_2(?i, ?l) ^ ~obj-break'(?i2) ^ cleaned'(?l))]]
// 			+ 50 * [sum_{?f: item, ?i: item, ?l: location} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ food-in(?f, ?i) ^ GOAL(?f, ?i, ?l))]
// 			+ 40 * [sum_{?a: agent, ?i: item, ?l: location} 
// 					(clean(?a, ?l) ^ obj-break'(?i) ^ obj-loc'(?i, ?l) ^ MOP_ITEM(?i))]

// 			// Penalty for uncleaned locations
// 			- 10 * [sum_{?l : location}(~cleaned(?l))]
// 			// Movement cost
// 			- [sum_{?a: agent, ?wf: location, ?wt: location} [COST(?a, ?wf, ?wt) * move(?a, ?wf, ?wt)]]
// 			// Penalty for picking or placing objects (encouraging minimal actions)
// 			- [sum_{?a: agent, ?i : item, ?l : location} [ [pick(?a, ?i, ?l) | place(?a, ?i, ?l)] ]];


// works for anticipatory rewards and penalties (but humand and robot picks up things right after right)
// reward =
// // Reward humans for placing items correctly
// + 100 * [sum_{?i: item} exists_{?l: location, ?h: human, ?a: agent} ((place_human(?h, ?i, ?l) | place(?a, ?i, ?l)) ^ obj-loc'(?i, ?l) ^ DESTINATION(?i, ?l))]

// // Reward robot for assisting humans by bringing items closer
// + 50 * [sum_{?a: agent, ?i: item, ?l: location} (pick(?a, ?i, ?l) ^ agent-loc(?a, ?l) ^ exists_{?h: human} (human-loc(?h, ?l)))]

// // Reward robot for picking up mop or broom in anticipation of cleaning
// + 40 * [sum_{?a: agent, ?m: item, ?l: location} (pick(?a, ?m, ?l) ^ MOP_ITEM(?m) ^ exists_{?h: human} (human-loc(?h, ?l)))]

// // Reward for robot handing objects to human instead of placing them
// + 30 * [sum_{?a: agent, ?i: item, ?h: human, ?l: location} (inhand(?a, ?i) ^ human-loc(?h, ?l) ^ obj-loc'(?i, ?l))]

// // Penalize the robot if it picks up something unnecessary
// - 20 * [sum_{?a: agent, ?i: item, ?l: location} (pick(?a, ?i, ?l) ^ ~exists_{?h: human} (human-loc(?h, ?l)))]

// // Small penalty for excessive movement (to avoid pointless wandering)
// - 10 * [sum_{?a: agent, ?l1: location, ?l2: location} (move(?a, ?l1, ?l2) ^ (COST(?a, ?l1, ?l2) > 10))];

// best one till now!!
reward =
        // // Reward for placing items correctly at their destination
        // + 80 * [sum_{?f: item} exists_{?l: location} (FOOD_ITEM(?f) ^ obj-loc'(?f, ?l) ^ DESTINATION(?f, ?l))]
        // + 80 * [sum_{?i: item} exists_{?l: location} (obj-loc'(?i, ?l) ^ DESTINATION_2(?i, ?l) ^ ~obj-break'(?i) ^ cleaned'(?l))]
        // + 200 * [sum_{?f: item, ?i: item, ?l: location} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ food-in'(?f, ?i) ^ GOAL(?f, ?i, ?l))]
        
        // // Reward for successfully picking and placing items
        // + 40 * [sum_{?a: agent, ?i: item, ?l: location} ((pick(?a, ?i, ?l) | place(?a, ?i, ?l)) ^ obj-loc'(?i, ?l))]
        // + 40 * [sum_{?i: item, ?l: location} exists_{?h: human} ((pick_human(?h, ?i, ?l) | place_human(?h, ?i, ?l)) ^ obj-loc'(?i, ?l))]
        // + 60 * [sum_{?a: agent, ?f: item, ?i: item} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in(?a, ?f, ?i) ^ food-in'(?f, ?i))]
        // + 60 * [sum_{?f: item, ?i: item} exists_{?h: human} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in_human(?h, ?f, ?i) ^ food-in'(?f, ?i))]

        // Reward for placing items correctly at their destination
        + 80 * [sum_{?f: item} exists_{?l: location} (FOOD_ITEM(?f) ^ obj-loc'(?f, ?l) ^ (DESTINATION_0(?f, ?l) ))]
        + 80 * [sum_{?i: item} exists_{?l: location} (obj-loc'(?i, ?l) ^ DESTINATION_0(?i, ?l) ^ ~obj-break'(?i) ^ cleaned'(?l))]
        + 200 * [sum_{?f: item, ?i: item, ?l: location} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ food-in'(?f, ?i) ^ (GOAL_0(?f, ?i, ?l) | GOAL_1(?f, ?i, ?l)))]

        // Reward for successfully picking and placing items
        + 40 * [sum_{?a: agent, ?i: item, ?l: location} ((pick(?a, ?i, ?l) | place(?a, ?i, ?l)) ^ obj-loc'(?i, ?l))]
        + 40 * [sum_{?i: item, ?l: location} exists_{?h: human, ?l1:location} ((pick_human(?h, ?i, ?l) | place_human(?h, ?i, ?l1)) ^ obj-loc'(?i, ?l))]
        + 60 * [sum_{?a: agent, ?f: item, ?i: item} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in(?a, ?f, ?i) ^ food-in'(?f, ?i))]
        + 60 * [sum_{?f: item, ?i: item} exists_{?h: human} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ put_in_human(?h, ?f, ?i) ^ food-in'(?f, ?i))]

                
        // Penalty for not cleaning up broken objects
        - 10 * [sum_{?l: location} (~cleaned(?l))]
        
        // Reward robot for picking up the mop OR moving toward fragile items if human is holding one
        + 40 * [sum_{?a: agent, ?m: item, ?l1: location, ?l2:location} exists_{?h: human, ?i: item} (inhand-human'(?h, ?i)) ^ ~MOP_ITEM(?i) ^ FRAGILE(?i) ^ (((pick(?a, ?m, ?l1) ^ MOP_ITEM(?m)) | move(?a, ?l1, ?l2)) ^ ~EQUAL(?i, ?m) ^ obj-loc'(?m, ?l1))]
        

        // Add a positive reward for switching an appliance ON if the agent is present
        + 5 * [ sum_{?a: agent, ?l: location}
        (agent_switch_on(?a, ?l) ^ APPLIANCE(?l) ^ agent-loc(?a, ?l)) ]

        // Also reward switching OFF an appliance if the agent is present
        + 5 * [ sum_{?a: agent, ?l: location}
        (agent_switch_off(?a, ?l) ^ APPLIANCE(?l) ^ agent-loc(?a, ?l)) ]

        // Similarly, reward the human for switching ON an appliance if they are present
        + 5 * [ sum_{?h: human, ?l: location}
        (human_switch_on(?h, ?l) ^ APPLIANCE(?l) ^ human-loc(?h, ?l)) ]

        // And reward the human for switching OFF if they are present
        + 5 * [ sum_{?h: human, ?l: location}
        (human_switch_off(?h, ?l) ^ APPLIANCE(?l) ^ human-loc(?h, ?l)) ]

        // REWARD: Agent (or human) opens an appliance
        + 5 * [ sum_{?a: agent, ?obj: location}
        (agent_open(?a, ?obj) ^ APPLIANCE(?obj) ^ agent-loc(?a, ?obj)) ]

        + 5 * [ sum_{?h: human, ?obj: location}
            (human_open(?h, ?obj) ^ APPLIANCE(?obj) ^ human-loc(?h, ?obj)) ]

        // REWARD: Agent (or human) closes an appliance
        + 5 * [ sum_{?a: agent, ?obj: location}
            (agent_close(?a, ?obj) ^ APPLIANCE(?obj) ^ agent-loc(?a, ?obj)) ]

        + 5 * [ sum_{?h: human, ?obj: location}
            (human_close(?h, ?obj) ^ APPLIANCE(?obj) ^ human-loc(?h, ?obj)) ]


    //     // Extra reward for picking a NEW appliance after a failure
    //     + 20 * [ sum_{?a: agent, ?l: location}
    //     (
    //     last_switch_failed(?a)      // last step we tried and failed
    //     ^ (agent_switch_on(?a, ?l) | agent_switch_off(?a, ?l))  // we try a new switch
    //     ^ (APPLIANCE(?l))
    //     ^ (~EQUAL_LOC(?l, last_switch_loc(?a)))  // must be a different location
    //     )
    // ]



        // Reward for assisting humans (picking or placing together)
        + 10 * [sum_{?a: agent, ?i: item, ?l: location} exists_{?h: human} 
                ((pick(?a, ?i, ?l) | pick_human(?h, ?i, ?l)) |
                 (place(?a, ?i, ?l) | place_human(?h, ?i, ?l)))]
        
        // Small penalty for excessive movement (to avoid pointless wandering)
        - 7 * [sum_{?a: agent, ?l1: location, ?l2: location} 
                (move(?a, ?l1, ?l2) & (COST(?a, ?l1, ?l2) > 10))];

   // + 100 * [ sum_{?a: agent, ?m: item, ?l: location}
    //     ( MOP_ITEM(?m) ^ obj-loc(?m, ?l) ^ agent-loc(?a, ?l)
    //       ^ exists_{?h: human} (human-loc(?h, ?l))
    //       ^ exists_{?x: item} (FRAGILE(?x) ^ obj-loc(?x, ?l))
    //     )
    // ]

    // - 50 * [ sum_{?l: location, ?i: item}
    //     exists_{?h: human} (
    //       FRAGILE(?i)
    //       ^ pick_human(?h, ?i, ?l)
    //       ^ ~exists_{?m: item} (MOP_ITEM(?m) ^ obj-loc(?m, ?l))
    //     )
    // ]

    // + 60 * [ sum_{?a: agent, ?i: item, ?l: location}
    //     ( pick(?a, ?i, ?l) ^ FRAGILE(?i)
    //       ^ exists_{?h: human} (human-loc(?h, ?l))
    //     )
    // ]

    // - 30 * [ sum_{?l: location, ?f: item}
    //     exists_{?h: human} (
    //       FOOD_ITEM(?f)
    //       ^ ( pick_human(?h, ?f, ?l) | place_human(?h, ?f, ?l) )
    //     )
    // ]

    // - 200 * [ sum_{?h: human, ?m: item, ?l: location}
    //     (
    //       pick_human(?h, ?m, ?l)
    //       ^ MOP_ITEM(?m)
    //     )
    // ]

// // anticipatory reward function; WORKING UNTIL ANTICIPATION BUT NOT TO DESTINATION OR GOAL
// reward = 

//     // // Reward for correctly placing objects at their destination
//     // + 80 * [sum_{?i: item, ?l: location} 
//     //         (obj-loc'(?i, ?l) ^ DESTINATION_2(?i, ?l) ^ ~obj-break'(?i)) ]

//     // // Reward for cleaning up broken objects
//     // + 30 * [sum_{?a: agent, ?i: item, ?l: location} 
//     // (clean(?a, ?l) ^ obj-break'(?i) ^ obj-loc'(?i, ?l))]

//     // Reward for correctly placing objects at their destination
//     + 50 * [sum_{?f: item} exists_{?l : location} (FOOD_ITEM(?f) ^ obj-loc'(?f, ?l) ^ DESTINATION(?f, ?l)) ]
//     + 50 * [sum_{?i: item} exists_{?i2:item, ?l : location}
//     ((obj-loc'(?i, ?l) ^ DESTINATION_2(?i, ?l) ^ ~obj-break'(?i) ^ cleaned'(?l))
//                 | (obj-loc'(?i2, ?l) ^ EQUAL(?i, ?i2) ^ DESTINATION_2(?i2, ?l) ^ ~obj-break'(?i2) ^ cleaned'(?l)))
//     ]
//     + 120 * [sum_{?f: item, ?i: item, ?l: location} (FOOD_ITEM(?f) ^ CONTAINER(?i) ^ food-in(?f, ?i) ^ GOAL(?f, ?i, ?l))]

//     // penalty for not cleaning
// 	- 10 * [sum_{?l : location}(~cleaned(?l))]


//     // Reward robot for picking up the mop OR moving toward fragile items if human is holding one
//     + 20 * [sum_{?a: agent, ?m: item, ?l: location} 
//             ((pick(?a, ?m, ?l) ^ MOP_ITEM(?m)) | move(?a, ?l, ?l)) ^ 
//             obj-loc'(?m, ?l) ^ exists_{?h: human, ?i : item} (inhand-human'(?h, ?i)) ^ FRAGILE(?i)]

//     // Reward for assisting humans (picking or placing together)
//     + 10 * [sum_{?a: agent, ?i: item, ?l: location} exists_{?h: human}
//             ((pick(?a, ?i, ?l) | pick_human(?h, ?i, ?l)) |
//              (place(?a, ?i, ?l) | place_human(?h, ?i, ?l)))]

//     // Small penalty for excessive movement (to avoid pointless wandering)
//     + 7 * [sum_{?a: agent, ?l1: location, ?l2: location} 
//             (move(?a, ?l1, ?l2) ^ (COST(?a, ?l1, ?l2) > 10))];




// joint action rewards
// reward = 

//     // Reward for placing objects correctly
//     + 20 * [sum_{?i: item} exists_{?l : location} (obj-loc'(?i, ?l) ^ DESTINATION(?i, ?l) ^ ~obj-break(?i) ^ cleaned'(?l)) ]

//     // Penalty for uncleaned locations
//     - 30 * [sum_{?l : location} (~cleaned'(?l)) ]           

//     // Movement cost of robot
//     - [sum_{?a: agent, ?wf: location, ?wt: location} [COST(?a, ?wf, ?wt) * move(?a, ?wf, ?wt)]]

//     //movement costs of rhuman
//     //- [sum_{?h : human, ?wf: location, ?wt: location} [COST_HUMAN(?h, ?wf, ?wt) * move_human(?h, ?wf, ?wt)]]

//     // Penalty for picking or placing objects (encouraging minimal actions)
//     + 10 * [sum_{?a: agent, ?i : item, ?l : location} [obj-loc'(?i, ?l) ^ agent-loc(?a, ?l) ^ (pick(?a, ?i, ?l) | place(?a, ?i, ?l)) ] ]
//     // + 30 * [sum_{?h: human, ?i : item, ?l : location} [obj-loc'(?i, ?l) ^ human-loc(?h, ?l) ^ (pick_human(?h, ?i, ?l) | place_human(?h, ?i, ?l)) ] ]

//     // Reduced penalty for picking a fragile item and failing (encourages learning recovery)
//     - 10 * [sum_{?a: agent, ?i: item, ?l: location} (obj-loc'(?i, ?l) ^ pick(?a, ?i, ?l) ^ agent-loc(?a, ?l) ^ ~inhand'(?a, ?i) ^ clean(?a, ?l) ^ FRAGILE(?i))]

//     // Reduced penalty for picking a fragile item and failing (encourages learning recovery)
//     //- 10 * [sum_{?h: human, ?i: item, ?l: location} (obj-loc'(?i, ?l) ^ pick_human(?h, ?i, ?l) ^ human-loc(?h, ?l) ^ ~inhand-human'(?h, ?i) ^ clean_human(?h, ?l) ^ FRAGILE(?i))]

//     // Moderate penalty for breaking a fragile item (allows breaking but discourages carelessness)
//     - 20 * [sum_{?i: item} (obj-break'(?i) ^ FRAGILE(?i))]

//     // Increased reward for picking up the mop as part of recovery
//     + 30 * [sum_{?a: agent, ?m: item, ?l: location} (obj-loc'(?m, ?l) ^ pick(?a, ?m, ?l) ^ agent-loc(?a, ?l) ^ ~inhand'(?a, ?m) ^ MOP_ITEM(?m) ^ clean(?a, ?l))]

//     // Stronger reward for cleaning up a broken object using a mop (encourages recovery)
//     + 50 * [sum_{?a: agent, ?i: item, ?l: location} (clean(?a, ?l) ^ obj-break(?i) ^ obj-loc'(?i, ?l) ^ MOP_ITEM(?i)) ];






    action-preconditions {


        forall_{?a: agent, ?i : item, ?l : location, ?h: human} [pick(?a, ?i, ?l) => agent-loc(?a, ?l) ^ obj-loc(?i, ?l) ^ ~obj-break(?i) ^ ~inhand-human(?h, ?i)];
        forall_{?a: agent, ?l1 : location, ?l2 : location} [move(?a, ?l1, ?l2) => ~agent-loc(?a, ?l2) ^ agent-loc(?a, ?l1)];
		forall_{?a: agent, ?i : item, ?l : location} [place(?a, ?i, ?l) => agent-loc(?a, ?l) ^ ~obj-loc(?i, ?l) ^ inhand(?a, ?i) ^ pick(?a, ?i, ?l)];
        forall_{?a: agent, ?f: item, ?i: item} [put_in(?a, ?f, ?i) => ~food-in(?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i) ^ [exists_{?l: location}(obj-loc(?i, ?l) ^ agent-loc(?a, ?l))] ^
												inhand(?a, ?f) ];
        forall_{?a: agent, ?l : location} [clean(?a, ?l) => agent-loc(?a, ?l) ^ exists_{?m: item} (inhand(?a, ?m) ^ MOP_ITEM(?m)) ];


        forall_{?a: agent, ?h: human, ?i : item, ?l : location} [pick_human(?h, ?i, ?l) => human-loc(?h, ?l) ^ obj-loc(?i, ?l) ^ ~obj-break(?i) ^ ~inhand(?a, ?i)];
        forall_{?h: human, ?l1 : location, ?l2 : location} [move_human(?h, ?l1, ?l2) => ~human-loc(?h, ?l2) ^ human-loc(?h, ?l1)];
        forall_{?h: human, ?i : item, ?l : location} [place_human(?h, ?i, ?l) => human-loc(?h, ?l) ^ ~obj-loc(?i, ?l) ^ inhand-human(?h, ?i)];
        forall_{?a: human, ?f: item, ?i: item} [put_in_human(?a, ?f, ?i) => ~food-in(?f, ?i) ^ FOOD_ITEM(?f) ^ CONTAINER(?i) ^ [exists_{?l: location}(obj-loc(?i, ?l) ^ human-loc(?a, ?l))] ^
                                                inhand-human(?a, ?f) ];
	
        forall_{?a: agent, ?app: location} [agent_switch_on(?a, ?app) => APPLIANCE(?app) ^ ~switch_appliance(?app) ^ agent-loc(?a, ?app)];

        forall_{?a: agent, ?app: location} [agent_switch_off(?a, ?app) => APPLIANCE(?app) ^ switch_appliance(?app) ^ agent-loc(?a, ?app)] ;

        forall_{?h: human, ?app: location} [human_switch_on(?h, ?app) => APPLIANCE(?app) ^ ~switch_appliance(?app) ^ human-loc(?h, ?app)]  ;

        forall_{?h: human, ?app: location} [human_switch_off(?h, ?app) => APPLIANCE(?app) ^ switch_appliance(?app) ^  human-loc(?h, ?app)]  ;

        forall_{?a: agent, ?app: location} [agent_open(?a, ?app) => APPLIANCE(?app) ^ ~open(?app) ^ agent-loc(?a, ?app)]; //What to open?

        forall_{?a: agent, ?app: location} [agent_close(?a, ?app) => APPLIANCE(?app) ^ open(?app) ^ agent-loc(?a, ?app)] ;

        forall_{?h: human, ?app: location} [human_open(?h, ?app) => APPLIANCE(?app) ^ ~open(?app) ^ human-loc(?h, ?app)];

        forall_{?h: human, ?app: location} [human_close(?h, ?app) => APPLIANCE(?app) ^ open(?app) ^ human-loc(?h, ?app)];

    };
}
domain cleaning_dishes_robot_anticipation {

    types {
        location : object;
        item : object;
        agent : object;
        human: object;
        interm_level : { @level0, @level1 };
        //container :  item;
    };

    pvariables {
        // State fluents
        current-level                      	: { state-fluent, interm_level, default = @level0 };
		manipulation						: {	state-fluent, bool, default = false}; // probability of success of manipulation task


        agent-loc(agent, location)			: { state-fluent, bool, default = false }; // agent at location
        human-loc(human, location)			: { state-fluent, bool, default = false }; // agent at location
        
        obj-loc(item, location)  : { state-fluent, bool, default = false };
        inhand(agent, item)      : { state-fluent, bool, default = false };
        inhand-human(human, item)      : { state-fluent, bool, default = false };
        obj-break(item)          : { state-fluent, bool, default = false };
        cleaned(location)        : { state-fluent, bool, default = true };

        // Action fluents
        move(agent, location, location) : { action-fluent, bool, default = false };
        move_human(human, location, location) : { action-fluent, bool, default = false };
        pick(agent, item, location)     : { action-fluent, bool, default = false };
        pick_human(human, item, location)     : { action-fluent, bool, default = false };
        place(agent, item, location)    : { action-fluent, bool, default = false };
        place_human(human, item, location)    : { action-fluent, bool, default = false };
        clean(agent, location)          : { action-fluent, bool, default = false };
        clean_human(human, location)          : { action-fluent, bool, default = false };

        // Non-fluent variables
        COST(agent, location, location) : { non-fluent, int, default = 0 };
        COST_HUMAN(human, location, location) : { non-fluent, int, default = 0 };
        FRAGILE(item)                   : { non-fluent, bool, default = false };
        DESTINATION(item, location)     : { non-fluent, bool, default = false };
        MOP_ITEM(item)                  : { non-fluent, bool, default = false };
        //GOAL_LOCATION(location)         : {  non-fluent, bool, default = false };
    };

    cpfs {

        current-level' =
            if (current-level == @level0) 
				then @level1
            else 
				@level0;

		manipulation' = 
			if (current-level == @level1)
				then Bernoulli(0.3)
			else
				manipulation;



        human-loc'(?h, ?l) =
            // If the human decides to move FROM a location
            if (exists_{?from : location} (move_human(?h, ?from, ?l) ^ Bernoulli(0.8) ^ human-loc(?h, ?from))) 
                then true  // 80% chance they reach `?l`
            
            // Did it leave ?l and become false?
			else if (exists_{?to : location} (move_human(?h, ?l, ?to) ^ human-loc(?h, ?l)))
				then false
                
            // If no movement happens, the human stays in their current location
            else 
                human-loc(?h, ?l);
    


        inhand'(?a, ?i) =
			if ( exists_{?l : location}( pick(?a, ?i, ?l) ))
				then true
			else if(exists_{?l : location}(place(?a, ?i, ?l) | inhand(?a, ?i)))
				then false
            else if(exists_{?h:human} (inhand-human(?h, ?i)))
                then false
			else
				inhand(?a, ?i);

        inhand-human'(?h, ?i) =
            if (exists_{?l : location}( pick_human(?h, ?i, ?l) ^ Bernoulli(0.1) ^ ((manipulation ^ FRAGILE(?i)) | ~FRAGILE(?i)) ))
                then true
            else if (exists_{?l : location}( pick_human(?h, ?i, ?l) ^ Bernoulli(0.9) ^ ((manipulation ^ FRAGILE(?i)) | ~FRAGILE(?i)) ))
                then false
            else if(exists_{?l : location}(place_human(?h, ?i, ?l) | inhand-human(?h, ?i)))
				then false
            else if(exists_{?a:agent} (inhand(?a, ?i)))
                then false
            else
                inhand-human(?h, ?i);

		obj-break'(?i) = 
			if(exists_{?h : human, ?l : location} ((pick_human(?h, ?i, ?l) ) ^ Bernoulli(0.9) ^ ~manipulation ^ FRAGILE(?i)))
				then true
            else if(exists_{?h : human, ?l : location} ((place_human(?h, ?i, ?l) | inhand-human(?h, ?i) ) ^ Bernoulli(0.9) ^ ~manipulation ^ FRAGILE(?i) ))
				then true
            else if(exists_{?a: agent, ?l : location} (pick(?a, ?i, ?l)))
                then false
            else if(exists_{?a : agent, ?l : location} (place(?a, ?i, ?l) | inhand(?a, ?i)))
				then false
            else if (exists_{?h: human, ?l : location} (pick_human(?h, ?i, ?l) ^ Bernoulli(0.1) ^ ~manipulation ^ ~FRAGILE(?i)))
                then false
            else if(exists_{?h : human, ?l : location} ((place_human(?h, ?i, ?l) | inhand-human(?h, ?i) ) ^ Bernoulli(0.1) ^ ~manipulation ^ ~FRAGILE(?i) ))
				then false
			else
				false;

        obj-loc'(?i, ?l) = 
            if (exists_{?a : agent} (pick(?a, ?i, ?l)))
                then false  // Robot picked up the item, remove from location
            else if (exists_{?h : human} (pick_human(?h, ?i, ?l) ))
                then false  // Human picked up the item, remove from location
            else if (exists_{?a : agent} (place(?a, ?i, ?l) ^ inhand(?a, ?i)))
                then true  // The item in the robot's hand is in obj-loc
            else if (exists_{?h : human} (place_human(?h, ?i, ?l) | inhand-human(?h, ?i)))
                then true  // The item is now in the human's hand
            else obj-loc(?i, ?l);  // Otherwise, the item stays in the same location
            


		

        agent-loc'(?a, ?l) = 		
			// Did it move to ?l and become true?
			if (exists_{?from : location} (move(?a, ?from, ?l) ^ agent-loc(?a, ?from)))
				then true
			
			// Did it leave ?l and become false?
			else if (exists_{?to : location} (move(?a, ?l, ?to) ^ agent-loc(?a, ?l)))
				then false
				
			// It didn't move, so it's current value persists (frame axiom)
			else 
				agent-loc(?a, ?l);

		cleaned'(?l) = 
            if (exists_{?i : item, ?a: agent} (obj-break(?i) ^ obj-loc(?i, ?l) ^ agent-loc(?a, ?l) ^ ~exists_{?m: item} (MOP_ITEM(?m) ^ obj-loc(?m, ?l) ^ agent-loc(?a, ?l))))
                then false  //Location remains dirty if no mop is there

            else if (exists_{?i : item, ?h: human} (obj-break(?i) ^ obj-loc(?i, ?l) ^ human-loc(?h, ?l) ^ ~exists_{?m: item} (MOP_ITEM(?m) ^ obj-loc(?m, ?l) ^ human-loc(?h, ?l))))
                then false  //Location remains dirty if no mop is there

            else if (exists_{?a : agent, ?i : item} (clean(?a, ?l) ^ agent-loc(?a, ?l) ^ obj-loc(?i, ?l) ^ MOP_ITEM(?i)))
                then true  // Location gets cleaned when using a mop

            else if (exists_{?h : human, ?i : item} (clean_human(?h, ?l) ^ human-loc(?h, ?l) ^ obj-loc(?i, ?l) ^ MOP_ITEM(?i)))
                then true  // Location gets cleaned when using a mop

            else
                cleaned(?l);


		
        
    };





// anticipatory reward function with correct rewards
reward = 

    // Reward for correctly placing objects at their destination
    + 80 * [sum_{?i: item, ?l: location} 
            (obj-loc'(?i, ?l) ^ DESTINATION(?i, ?l) ^ ~obj-break'(?i)) ]

    // Reward for cleaning up broken objects
    + 30 * [sum_{?a: agent, ?i: item, ?l: location} 
            (clean(?a, ?l) ^ obj-break'(?i) ^ obj-loc'(?i, ?l))]

    // Reward robot for picking up the mop OR moving toward fragile items if human is holding one
    + 30 * [sum_{?a: agent, ?m: item, ?l: location} 
            ((pick(?a, ?m, ?l) ^ MOP_ITEM(?m)) | move(?a, ?l, ?l)) ^ 
            obj-loc'(?m, ?l) ^ exists_{?h: human, ?i : item} (inhand-human'(?h, ?i)) ^ FRAGILE(?i)]

    // Reward for assisting humans (picking or placing together)
    + 8 * [sum_{?a: agent, ?i: item, ?l: location} exists_{?h: human}
            ((pick(?a, ?i, ?l) | pick_human(?h, ?i, ?l)) |
             (place(?a, ?i, ?l) | place_human(?h, ?i, ?l)))]

    // Small penalty for excessive movement (to avoid pointless wandering)
    + 7 * [sum_{?a: agent, ?l1: location, ?l2: location} 
            (move(?a, ?l1, ?l2) ^ (COST(?a, ?l1, ?l2) > 10))];




// joint action rewards
// reward = 

//     // Reward for placing objects correctly
//     + 20 * [sum_{?i: item} exists_{?l : location} (obj-loc'(?i, ?l) ^ DESTINATION(?i, ?l) ^ ~obj-break(?i) ^ cleaned'(?l)) ]

//     // Penalty for uncleaned locations
//     - 30 * [sum_{?l : location} (~cleaned'(?l)) ]           

//     // Movement cost of robot
//     - [sum_{?a: agent, ?wf: location, ?wt: location} [COST(?a, ?wf, ?wt) * move(?a, ?wf, ?wt)]]

//     //movement costs of rhuman
//     //- [sum_{?h : human, ?wf: location, ?wt: location} [COST_HUMAN(?h, ?wf, ?wt) * move_human(?h, ?wf, ?wt)]]

//     // Penalty for picking or placing objects (encouraging minimal actions)
//     + 10 * [sum_{?a: agent, ?i : item, ?l : location} [obj-loc'(?i, ?l) ^ agent-loc(?a, ?l) ^ (pick(?a, ?i, ?l) | place(?a, ?i, ?l)) ] ]
//     // + 30 * [sum_{?h: human, ?i : item, ?l : location} [obj-loc'(?i, ?l) ^ human-loc(?h, ?l) ^ (pick_human(?h, ?i, ?l) | place_human(?h, ?i, ?l)) ] ]

//     // Reduced penalty for picking a fragile item and failing (encourages learning recovery)
//     - 10 * [sum_{?a: agent, ?i: item, ?l: location} (obj-loc'(?i, ?l) ^ pick(?a, ?i, ?l) ^ agent-loc(?a, ?l) ^ ~inhand'(?a, ?i) ^ clean(?a, ?l) ^ FRAGILE(?i))]

//     // Reduced penalty for picking a fragile item and failing (encourages learning recovery)
//     //- 10 * [sum_{?h: human, ?i: item, ?l: location} (obj-loc'(?i, ?l) ^ pick_human(?h, ?i, ?l) ^ human-loc(?h, ?l) ^ ~inhand-human'(?h, ?i) ^ clean_human(?h, ?l) ^ FRAGILE(?i))]

//     // Moderate penalty for breaking a fragile item (allows breaking but discourages carelessness)
//     - 20 * [sum_{?i: item} (obj-break'(?i) ^ FRAGILE(?i))]

//     // Increased reward for picking up the mop as part of recovery
//     + 30 * [sum_{?a: agent, ?m: item, ?l: location} (obj-loc'(?m, ?l) ^ pick(?a, ?m, ?l) ^ agent-loc(?a, ?l) ^ ~inhand'(?a, ?m) ^ MOP_ITEM(?m) ^ clean(?a, ?l))]

//     // Stronger reward for cleaning up a broken object using a mop (encourages recovery)
//     + 50 * [sum_{?a: agent, ?i: item, ?l: location} (clean(?a, ?l) ^ obj-break(?i) ^ obj-loc'(?i, ?l) ^ MOP_ITEM(?i)) ];






    action-preconditions {


        forall_{?a: agent, ?i : item, ?l : location, ?h: human} [pick(?a, ?i, ?l) => agent-loc(?a, ?l) ^ obj-loc(?i, ?l) ^ ~obj-break(?i) ^ ~inhand-human(?h, ?i)];
        forall_{?a: agent, ?l1 : location, ?l2 : location} [move(?a, ?l1, ?l2) => ~agent-loc(?a, ?l2) ^ agent-loc(?a, ?l1)];
		forall_{?a: agent, ?i : item, ?l : location} [place(?a, ?i, ?l) => agent-loc(?a, ?l) ^ ~obj-loc(?i, ?l) ^ inhand(?a, ?i)];

        forall_{?a: agent, ?h: human, ?i : item, ?l : location} [pick_human(?h, ?i, ?l) => human-loc(?h, ?l) ^ obj-loc(?i, ?l) ^ ~obj-break(?i) ^ ~inhand(?a, ?i)];
        forall_{?h: human, ?l1 : location, ?l2 : location} [move_human(?h, ?l1, ?l2) => ~human-loc(?h, ?l2) ^ human-loc(?h, ?l1)];
        forall_{?h: human, ?i : item, ?l : location} [place_human(?h, ?i, ?l) => human-loc(?h, ?l) ^ ~obj-loc(?i, ?l) ^ inhand-human(?h, ?i)];
		forall_{?a: agent, ?l : location} [clean(?a, ?l) => agent-loc(?a, ?l) ^ exists_{?m: item} (inhand(?a, ?m) ^ MOP_ITEM(?m)) ];

    };
}
